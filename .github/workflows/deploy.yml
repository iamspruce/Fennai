name: Deploy to Firebase & Cloud Run
on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]

jobs:
  deploy-hosting:
    name: Deploy Frontend (Firebase Hosting)
    runs-on: ubuntu-latest
    if: ${{ github.ref == 'refs/heads/main' && startsWith(github.event.head_commit.message, 'deploy:hosting') }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
      
      - name: Install dependencies
        run: npm ci
      
      - name: Create .env file
        run: |
          echo "${{ secrets.ENV_FILE }}" > .env
          echo ".env created."
      
      - name: Deploy to Firebase Hosting
        uses: FirebaseExtended/action-hosting-deploy@v0
        with:
          repoToken: ${{ secrets.GITHUB_TOKEN }}
          firebaseServiceAccount: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
          projectId: fennai
          channelId: live
        env:
          FIREBASE_CLI_EXPERIMENTS: webframeworks

  deploy-backend:
    name: Deploy Functions + Cloud Run GPU Inference
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
      
      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
      
      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: fennai
      
      - name: Install Firebase CLI
        run: npm install -g firebase-tools
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Setup Python virtual environment for proxy function
        run: |
          cd functions/proxy
          python3.10 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # ==================== STORAGE BUCKETS ====================
      
      - name: Create Voice Output Bucket
        run: |
          BUCKET_NAME="fennai-voice-output"
          REGION="us-central1"
          if gsutil ls -b gs://$BUCKET_NAME 2>/dev/null; then
            echo "âœ“ Bucket gs://$BUCKET_NAME already exists"
          else
            echo "Creating bucket gs://$BUCKET_NAME"
            gsutil mb -p fennai -c STANDARD -l $REGION gs://$BUCKET_NAME
            echo "âœ“ Bucket created successfully"
          fi
          # 24-hour lifecycle policy
          echo '{
            "lifecycle": {
              "rule": [{
                "action": {"type": "Delete"},
                "condition": {"age": 1}
              }]
            }
          }' > lifecycle.json
          gsutil lifecycle set lifecycle.json gs://$BUCKET_NAME
          echo "âœ“ Lifecycle policy set (24-hour auto-delete)"
          rm lifecycle.json

      - name: Create Dubbing Temp Bucket
        run: |
          BUCKET_NAME="fennai-dubbing-temp"
          REGION="us-central1"
          if gsutil ls -b gs://$BUCKET_NAME 2>/dev/null; then
            echo "âœ“ Bucket gs://$BUCKET_NAME already exists"
          else
            echo "Creating bucket gs://$BUCKET_NAME"
            gsutil mb -p fennai -c STANDARD -l $REGION gs://$BUCKET_NAME
            echo "âœ“ Bucket created successfully"
          fi
          # 7-day lifecycle policy for dubbing files
          echo '{
            "lifecycle": {
              "rule": [{
                "action": {"type": "Delete"},
                "condition": {"age": 7}
              }]
            }
          }' > lifecycle.json
          gsutil lifecycle set lifecycle.json gs://$BUCKET_NAME
          echo "âœ“ Lifecycle policy set (7-day auto-delete)"
          rm lifecycle.json

      # ==================== CLOUD TASKS QUEUE ====================
      
      - name: Create Cloud Tasks Queue
        run: |
          QUEUE_NAME="voice-generation-queue"
          LOCATION="us-central1"
          if gcloud tasks queues describe $QUEUE_NAME --location=$LOCATION 2>/dev/null; then
            echo "âœ“ Queue $QUEUE_NAME already exists"
          else
            echo "Creating Cloud Tasks queue..."
            gcloud tasks queues create $QUEUE_NAME \
              --location=$LOCATION \
              --max-dispatches-per-second=10 \
              --max-concurrent-dispatches=5 \
              --max-attempts=3 \
              --min-backoff=10s \
              --max-backoff=300s \
              --max-doublings=3 \
              --max-retry-duration=1800s
            echo "âœ“ Queue created successfully"
          fi

      # ==================== CLOUD RUN INFERENCE ====================
      
      - name: Build GPU Inference Image (with FFmpeg + Resemblyzer)
        run: |
          echo "Building Docker image with model + FFmpeg + Resemblyzer..."
          echo "âš ï¸ This will take ~90-120 seconds"
          gcloud builds submit \
            --config functions/inference/cloudbuild.yaml \
            --timeout=2400s \
            --substitutions _HF_TOKEN=${{ secrets.HF_TOKEN }} \
            functions/inference

      - name: Deploy Inference to Cloud Run
        id: deploy_run
        run: |
          URL=$(gcloud run deploy fennai-inference \
              --image gcr.io/fennai/fennai-inference:latest \
              --platform managed \
              --region us-central1 \
              --execution-environment gen2 \
              --allow-unauthenticated \
              --cpu 8 \
              --memory 32Gi \
              --gpu 1 \
              --gpu-type nvidia-l4 \
              --no-gpu-zonal-redundancy \
              --max-instances 3 \
              --min-instances 0 \
              --timeout 900s \
              --port 8080 \
              --cpu-boost \
              --concurrency=1 \
              --set-env-vars INTERNAL_TOKEN=${{ secrets.INTERNAL_TOKEN }},MODEL_NAME=microsoft/VibeVoice-1.5B,GCS_BUCKET=fennai-voice-output,GCS_DUBBING_BUCKET=fennai-dubbing-temp,GCP_PROJECT=fennai,QUEUE_LOCATION=us-central1,QUEUE_NAME=voice-generation-queue \
              --quiet \
              --format='value(status.url)')
          echo "CLOUD_RUN_URL=$URL" >> $GITHUB_OUTPUT
          echo "CLOUD_RUN_URL=$URL" >> $GITHUB_ENV

      - name: Get Cloud Run Service Account
        id: get_sa
        run: |
          SA=$(gcloud run services describe fennai-inference \
              --region=us-central1 \
              --format='value(spec.template.spec.serviceAccountName)')
          echo "SERVICE_ACCOUNT=$SA" >> $GITHUB_OUTPUT
          echo "Service Account: $SA"

      - name: Grant Storage Permissions to Cloud Run
        run: |
          SA="${{ steps.get_sa.outputs.SERVICE_ACCOUNT }}"
          gsutil iam ch serviceAccount:${SA}:objectAdmin gs://fennai-voice-output
          gsutil iam ch serviceAccount:${SA}:objectAdmin gs://fennai-dubbing-temp
          echo "âœ“ Storage permissions granted"

      - name: Grant Cloud Tasks Permissions
        run: |
          SA="${{ steps.get_sa.outputs.SERVICE_ACCOUNT }}"
          gcloud projects add-iam-policy-binding fennai \
            --member="serviceAccount:${SA}" \
            --role="roles/cloudtasks.enqueuer"
          echo "âœ“ Cloud Tasks permissions granted"

      - name: Enable Required APIs
        run: |
          gcloud services enable speech.googleapis.com
          gcloud services enable translate.googleapis.com
          gcloud services enable cloudtasks.googleapis.com
          echo "âœ“ APIs enabled"

      - name: Verify Deployment
        run: |
          echo "Waiting for Cloud Run to be ready..."
          sleep 15
          HEALTH_URL="${{ steps.deploy_run.outputs.CLOUD_RUN_URL }}/health"
          RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 15 "$HEALTH_URL" || echo "000")
          if [ "$RESPONSE" = "200" ]; then
            echo "âœ“ Cloud Run is healthy"
          else
            echo "âš ï¸ Unexpected response: $RESPONSE"
            echo "Cloud Run may still be initializing"
          fi

      # ==================== PROXY FUNCTIONS ====================

      - name: Create .env for proxy function
        run: |
          cd functions/proxy
          echo "CLOUD_RUN_URL=${{ steps.deploy_run.outputs.CLOUD_RUN_URL }}" > .env
          echo "INTERNAL_TOKEN=${{ secrets.INTERNAL_TOKEN }}" >> .env
          echo "GCP_PROJECT=fennai" >> .env
          echo "QUEUE_LOCATION=us-central1" >> .env
          echo "QUEUE_NAME=voice-generation-queue" >> .env
          echo "SERVICE_ACCOUNT_EMAIL=${{ steps.get_sa.outputs.SERVICE_ACCOUNT }}" >> .env
          echo "GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}" >> .env
          echo "GCS_DUBBING_BUCKET=fennai-dubbing-temp" >> .env

      - name: Deploy Proxy Functions
        run: |
          firebase deploy \
              --only functions \
              --project fennai \
              --non-interactive

      # ==================== DEPLOYMENT SUMMARY ====================

      - name: Deployment Summary
        run: |
          echo "================================"
          echo "ðŸš€ DEPLOYMENT SUCCESSFUL"
          echo "================================"
          echo ""
          echo "Cloud Run URL: ${{ steps.deploy_run.outputs.CLOUD_RUN_URL }}"
          echo ""
          echo "Features:"
          echo " â€¢ Voice Cloning (original)"
          echo " â€¢ Script Generator (Gemini 1.5 Pro)"
          echo " â€¢ Audio Dubbing (STT + Resemblyzer + Translation)"
          echo " â€¢ Video Dubbing (FFmpeg audio replacement)"
          echo ""
          echo "Architecture:"
          echo " â€¢ Model: Baked into Docker (~3GB)"
          echo " â€¢ Audio/Video: FFmpeg in container"
          echo " â€¢ Speaker Clustering: Resemblyzer + HDBSCAN"
          echo " â€¢ Storage: 2 GCS buckets (24hr + 7day lifecycle)"
          echo " â€¢ Queue: Cloud Tasks (async processing)"
          echo ""
          echo "Performance:"
          echo " â€¢ Cold start: 10-15s (model + FFmpeg)"
          echo " â€¢ Warm inference: <2s"
          echo " â€¢ Max concurrency: 1 per instance"
          echo " â€¢ Max instances: 3"
          echo ""
          echo "================================"